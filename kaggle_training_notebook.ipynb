{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ›°ï¸ SNUNet Change Detection - Kaggle Training\n",
                "\n",
                "**Setup:**\n",
                "1. Settings â†’ Accelerator â†’ **GPU T4 x2**\n",
                "2. Add Data â†’ Upload **LEVIR-CD-kaggle.zip** as dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SETUP ===\n",
                "import os, torch, torch.nn as nn, torch.nn.functional as F, numpy as np, zipfile\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "if device.type == 'cpu': print(\"âš ï¸ Enable GPU: Settings â†’ Accelerator â†’ GPU T4\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === EXTRACT DATASET ===\n",
                "DATA_ROOT = '/kaggle/working/data'\n",
                "\n",
                "# Find and extract zip from input\n",
                "if not os.path.exists(os.path.join(DATA_ROOT, 'train', 'A')):\n",
                "    zip_path = None\n",
                "    if os.path.exists('/kaggle/input'):\n",
                "        for d in os.listdir('/kaggle/input'):\n",
                "            for f in os.listdir(os.path.join('/kaggle/input', d)):\n",
                "                if f.endswith('.zip'):\n",
                "                    zip_path = os.path.join('/kaggle/input', d, f)\n",
                "                    break\n",
                "            # Also check if data is already extracted in input\n",
                "            check_path = os.path.join('/kaggle/input', d)\n",
                "            if os.path.exists(os.path.join(check_path, 'train', 'A')):\n",
                "                DATA_ROOT = check_path\n",
                "                print(f\"âœ… Found extracted data at: {DATA_ROOT}\")\n",
                "                break\n",
                "    \n",
                "    if zip_path and not os.path.exists(os.path.join(DATA_ROOT, 'train', 'A')):\n",
                "        print(f\"Extracting {zip_path}...\")\n",
                "        os.makedirs(DATA_ROOT, exist_ok=True)\n",
                "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
                "            z.extractall(DATA_ROOT)\n",
                "        print(\"âœ… Extracted!\")\n",
                "    elif not os.path.exists(os.path.join(DATA_ROOT, 'train', 'A')):\n",
                "        print(\"âŒ No dataset found. Upload LEVIR-CD-kaggle.zip to Add Data.\")\n",
                "        raise FileNotFoundError(\"Dataset not found\")\n",
                "\n",
                "# Find nested folder if exists\n",
                "for sub in ['', 'LEVIR-CD-patches', 'LEVIR-CD']:\n",
                "    check = os.path.join(DATA_ROOT, sub) if sub else DATA_ROOT\n",
                "    if os.path.exists(os.path.join(check, 'train', 'A')):\n",
                "        DATA_ROOT = check\n",
                "        break\n",
                "\n",
                "print(f\"Data: {DATA_ROOT}\")\n",
                "for s in ['train','val','test']:\n",
                "    p = os.path.join(DATA_ROOT, s, 'A')\n",
                "    if os.path.exists(p): print(f\"  {s}: {len(os.listdir(p))}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MODEL ===\n",
                "class CB(nn.Module):\n",
                "    def __init__(self,i,o): super().__init__(); self.c=nn.Sequential(nn.Conv2d(i,o,3,padding=1),nn.BatchNorm2d(o),nn.ReLU(True),nn.Conv2d(o,o,3,padding=1),nn.BatchNorm2d(o),nn.ReLU(True))\n",
                "    def forward(self,x): return self.c(x)\n",
                "class At(nn.Module):\n",
                "    def __init__(self,c): super().__init__(); self.a=nn.Sequential(nn.AdaptiveAvgPool2d(1),nn.Conv2d(c,c//8,1),nn.ReLU(),nn.Conv2d(c//8,c,1),nn.Sigmoid())\n",
                "    def forward(self,x): return x*self.a(x)\n",
                "class SNUNet(nn.Module):\n",
                "    def __init__(self,c=32):\n",
                "        super().__init__()\n",
                "        self.e1,self.e2,self.e3,self.e4,self.e5=CB(3,c),CB(c,c*2),CB(c*2,c*4),CB(c*4,c*8),CB(c*8,c*16)\n",
                "        self.pool=nn.MaxPool2d(2)\n",
                "        self.u4,self.d4,self.a4=nn.ConvTranspose2d(c*16,c*8,2,2),CB(c*24,c*8),At(c*8)\n",
                "        self.u3,self.d3,self.a3=nn.ConvTranspose2d(c*8,c*4,2,2),CB(c*12,c*4),At(c*4)\n",
                "        self.u2,self.d2,self.a2=nn.ConvTranspose2d(c*4,c*2,2,2),CB(c*6,c*2),At(c*2)\n",
                "        self.u1,self.d1,self.a1=nn.ConvTranspose2d(c*2,c,2,2),CB(c*3,c),At(c)\n",
                "        self.out=nn.Conv2d(c,1,1)\n",
                "    def forward(self,x1,x2):\n",
                "        e11,e12=self.e1(x1),self.e1(x2)\n",
                "        e21,e22=self.e2(self.pool(e11)),self.e2(self.pool(e12))\n",
                "        e31,e32=self.e3(self.pool(e21)),self.e3(self.pool(e22))\n",
                "        e41,e42=self.e4(self.pool(e31)),self.e4(self.pool(e32))\n",
                "        e51,e52=self.e5(self.pool(e41)),self.e5(self.pool(e42))\n",
                "        d=torch.abs(e51-e52)\n",
                "        d=self.a4(self.d4(torch.cat([self.u4(d),e41,e42],1)))\n",
                "        d=self.a3(self.d3(torch.cat([self.u3(d),e31,e32],1)))\n",
                "        d=self.a2(self.d2(torch.cat([self.u2(d),e21,e22],1)))\n",
                "        d=self.a1(self.d1(torch.cat([self.u1(d),e11,e12],1)))\n",
                "        return self.out(d)\n",
                "model=SNUNet(32).to(device)\n",
                "print(f\"âœ… Model: {sum(p.numel() for p in model.parameters()):,} params\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === DATASET ===\n",
                "class CD(Dataset):\n",
                "    def __init__(self,r,s): self.r,self.s=r,s; self.f=sorted([x for x in os.listdir(os.path.join(r,s,'A')) if x.endswith('.png')])\n",
                "    def __len__(self): return len(self.f)\n",
                "    def __getitem__(self,i):\n",
                "        n=self.f[i]\n",
                "        i1=np.array(Image.open(os.path.join(self.r,self.s,'A',n)).convert('RGB').resize((256,256)))\n",
                "        i2=np.array(Image.open(os.path.join(self.r,self.s,'B',n)).convert('RGB').resize((256,256)))\n",
                "        lb=np.array(Image.open(os.path.join(self.r,self.s,'label',n)).convert('L').resize((256,256)))\n",
                "        return torch.from_numpy(i1).permute(2,0,1).float()/255,torch.from_numpy(i2).permute(2,0,1).float()/255,(torch.from_numpy(lb).float()/255>0.5).float().unsqueeze(0)\n",
                "\n",
                "train_ds=CD(DATA_ROOT,'train')\n",
                "val_s='val' if os.path.exists(os.path.join(DATA_ROOT,'val','A')) else 'test'\n",
                "val_ds=CD(DATA_ROOT,val_s)\n",
                "train_ld=DataLoader(train_ds,8,shuffle=True,num_workers=2,pin_memory=True)\n",
                "val_ld=DataLoader(val_ds,16,num_workers=2)\n",
                "print(f\"âœ… Train:{len(train_ds)} Val:{len(val_ds)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === TRAINING ===\n",
                "import csv\n",
                "def loss_fn(p,t): return F.binary_cross_entropy_with_logits(p,t)+1-(2*(torch.sigmoid(p)*t).sum()+1)/(torch.sigmoid(p).sum()+t.sum()+1)\n",
                "def f1(p,t): p=(torch.sigmoid(p)>0.5).float(); tp=(p*t).sum(); return (2*tp/(2*tp+(p*(1-t)).sum()+((1-p)*t).sum()+1e-8)).item()\n",
                "\n",
                "opt=torch.optim.AdamW(model.parameters(),1e-4,weight_decay=1e-4)\n",
                "sched=torch.optim.lr_scheduler.CosineAnnealingLR(opt,100)\n",
                "os.makedirs('/kaggle/working/ckpt',exist_ok=True)\n",
                "log=open('/kaggle/working/ckpt/log.csv','w'); w=csv.writer(log); w.writerow(['ep','tr','va','f1'])\n",
                "\n",
                "best,pat=0,0\n",
                "for ep in range(100):\n",
                "    model.train(); tr=0\n",
                "    for x1,x2,y in tqdm(train_ld,desc=f\"Ep{ep+1}\",leave=False):\n",
                "        x1,x2,y=x1.to(device),x2.to(device),y.to(device)\n",
                "        opt.zero_grad(); out=model(x1,x2); L=loss_fn(out,y); L.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(),1); opt.step(); tr+=L.item()\n",
                "    tr/=len(train_ld)\n",
                "    model.eval(); va,f1s=0,0\n",
                "    with torch.no_grad():\n",
                "        for x1,x2,y in val_ld:\n",
                "            x1,x2,y=x1.to(device),x2.to(device),y.to(device); out=model(x1,x2); va+=loss_fn(out,y).item(); f1s+=f1(out,y)\n",
                "    va/=len(val_ld); f1s/=len(val_ld); sched.step()\n",
                "    print(f\"Ep{ep+1:3d}|TrL:{tr:.4f}|VaL:{va:.4f}|F1:{f1s:.4f}\")\n",
                "    w.writerow([ep+1,tr,va,f1s]); log.flush()\n",
                "    if f1s>best: best,pat=f1s,0; torch.save(model.state_dict(),'/kaggle/working/ckpt/best.pth'); print(f\"  >>Saved F1={f1s:.4f}\")\n",
                "    else: pat+=1\n",
                "    if pat>=20: print(\"Early stop!\"); break\n",
                "log.close(); print(f\"\\nâœ… Best F1: {best:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === RESULTS ===\n",
                "import matplotlib.pyplot as plt, pandas as pd\n",
                "model.load_state_dict(torch.load('/kaggle/working/ckpt/best.pth')); model.eval()\n",
                "df=pd.read_csv('/kaggle/working/ckpt/log.csv')\n",
                "fig,ax=plt.subplots(1,2,figsize=(12,4))\n",
                "ax[0].plot(df['ep'],df['tr'],label='Train'); ax[0].plot(df['ep'],df['va'],label='Val'); ax[0].legend(); ax[0].set_title('Loss')\n",
                "ax[1].plot(df['ep'],df['f1'],'g-'); ax[1].axhline(0.85,color='r',ls='--'); ax[1].set_title(f'F1 (Best:{df.f1.max():.4f})')\n",
                "plt.tight_layout(); plt.savefig('/kaggle/working/curves.png'); plt.show()\n",
                "\n",
                "fig,ax=plt.subplots(3,4,figsize=(12,9))\n",
                "for r in range(3):\n",
                "    x1,x2,y=val_ds[r*5]\n",
                "    with torch.no_grad(): p=(torch.sigmoid(model(x1.unsqueeze(0).to(device),x2.unsqueeze(0).to(device)))>0.5).cpu().squeeze().numpy()\n",
                "    ax[r,0].imshow(x1.permute(1,2,0)); ax[r,1].imshow(x2.permute(1,2,0)); ax[r,2].imshow(y.squeeze(),cmap='gray'); ax[r,3].imshow(p,cmap='gray')\n",
                "    for c in range(4): ax[r,c].axis('off')\n",
                "ax[0,0].set_title('T1'); ax[0,1].set_title('T2'); ax[0,2].set_title('GT'); ax[0,3].set_title('Pred')\n",
                "plt.tight_layout(); plt.savefig('/kaggle/working/preds.png'); plt.show()\n",
                "print(\"âœ… Done!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}