{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ›°ï¸ SNUNet-CBAM Training on LEVIR-CD\n",
                "\n",
                "## âš ï¸ SETUP REQUIRED:\n",
                "1. **Enable GPU**: Settings â†’ Accelerator â†’ **GPU T4 x2**\n",
                "2. **Enable Internet**: Settings â†’ Internet â†’ **On**\n",
                "3. Then run all cells\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU\n",
                "import torch\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    raise RuntimeError(\"GPU NOT ENABLED! Go to Settings -> Accelerator -> GPU T4\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download LEVIR-CD dataset\n",
                "!pip install -q gdown\n",
                "import gdown\n",
                "import zipfile\n",
                "import os\n",
                "\n",
                "DATA_DIR = '/kaggle/working/LEVIR-CD'\n",
                "if not os.path.exists(DATA_DIR):\n",
                "    print(\"Downloading LEVIR-CD...\")\n",
                "    # LEVIR-CD 256x256 patches\n",
                "    gdown.download('https://drive.google.com/uc?id=1786BQHZyPalR38ZVWL4Y0Rl8tD-Y1pwC', 'levir.zip', quiet=False)\n",
                "    with zipfile.ZipFile('levir.zip', 'r') as z:\n",
                "        z.extractall('/kaggle/working')\n",
                "    os.remove('levir.zip')\n",
                "    print(\"âœ… Done!\")\n",
                "else:\n",
                "    print(\"âœ… Dataset exists\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find data\n",
                "import os\n",
                "for root, dirs, files in os.walk('/kaggle/working'):\n",
                "    if 'A' in dirs and 'B' in dirs:\n",
                "        DATA_ROOT = os.path.dirname(root)\n",
                "        break\n",
                "print(f\"Data: {DATA_ROOT}\")\n",
                "\n",
                "# Create lists\n",
                "for split in ['train', 'val', 'test']:\n",
                "    p = os.path.join(DATA_ROOT, split, 'A')\n",
                "    if os.path.exists(p):\n",
                "        files = sorted([f for f in os.listdir(p) if f.endswith('.png')])\n",
                "        with open(f'/kaggle/working/{split}.txt', 'w') as out:\n",
                "            for f in files:\n",
                "                out.write(f\"{split}/A/{f} {split}/B/{f} {split}/label/{f}\\n\")\n",
                "        print(f\"{split}: {len(files)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "class CBAM(nn.Module):\n",
                "    def __init__(self, c):\n",
                "        super().__init__()\n",
                "        self.ca = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(c, c//16, 1), nn.ReLU(), nn.Conv2d(c//16, c, 1), nn.Sigmoid())\n",
                "        self.sa = nn.Sequential(nn.Conv2d(2, 1, 7, padding=3), nn.Sigmoid())\n",
                "    def forward(self, x):\n",
                "        x = x * self.ca(x)\n",
                "        return x * self.sa(torch.cat([x.mean(1,keepdim=True), x.max(1,keepdim=True)[0]], 1))\n",
                "\n",
                "class ConvBlock(nn.Module):\n",
                "    def __init__(self, i, o):\n",
                "        super().__init__()\n",
                "        self.c = nn.Sequential(nn.Conv2d(i,o,3,padding=1), nn.BatchNorm2d(o), nn.ReLU(), nn.Conv2d(o,o,3,padding=1), nn.BatchNorm2d(o), nn.ReLU())\n",
                "    def forward(self, x): return self.c(x)\n",
                "\n",
                "class SNUNet(nn.Module):\n",
                "    def __init__(self, c=32):\n",
                "        super().__init__()\n",
                "        self.e1,self.e2,self.e3,self.e4,self.e5 = ConvBlock(3,c), ConvBlock(c,c*2), ConvBlock(c*2,c*4), ConvBlock(c*4,c*8), ConvBlock(c*8,c*16)\n",
                "        self.pool = nn.MaxPool2d(2)\n",
                "        self.u4,self.d4,self.a4 = nn.ConvTranspose2d(c*16,c*8,2,2), ConvBlock(c*24,c*8), CBAM(c*8)\n",
                "        self.u3,self.d3,self.a3 = nn.ConvTranspose2d(c*8,c*4,2,2), ConvBlock(c*12,c*4), CBAM(c*4)\n",
                "        self.u2,self.d2,self.a2 = nn.ConvTranspose2d(c*4,c*2,2,2), ConvBlock(c*6,c*2), CBAM(c*2)\n",
                "        self.u1,self.d1,self.a1 = nn.ConvTranspose2d(c*2,c,2,2), ConvBlock(c*3,c), CBAM(c)\n",
                "        self.out = nn.Conv2d(c,1,1)\n",
                "\n",
                "    def forward(self, x1, x2):\n",
                "        e11,e12 = self.e1(x1), self.e1(x2)\n",
                "        e21,e22 = self.e2(self.pool(e11)), self.e2(self.pool(e12))\n",
                "        e31,e32 = self.e3(self.pool(e21)), self.e3(self.pool(e22))\n",
                "        e41,e42 = self.e4(self.pool(e31)), self.e4(self.pool(e32))\n",
                "        e51,e52 = self.e5(self.pool(e41)), self.e5(self.pool(e42))\n",
                "        d = torch.abs(e51-e52)\n",
                "        d = self.a4(self.d4(torch.cat([self.u4(d),e41,e42],1)))\n",
                "        d = self.a3(self.d3(torch.cat([self.u3(d),e31,e32],1)))\n",
                "        d = self.a2(self.d2(torch.cat([self.u2(d),e21,e22],1)))\n",
                "        d = self.a1(self.d1(torch.cat([self.u1(d),e11,e12],1)))\n",
                "        return self.out(d)\n",
                "\n",
                "print(f\"Params: {sum(p.numel() for p in SNUNet().parameters()):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "import numpy as np\n",
                "\n",
                "class CDData(Dataset):\n",
                "    def __init__(self, root, lst):\n",
                "        self.root = root\n",
                "        with open(lst) as f: self.items = [l.strip().split() for l in f]\n",
                "    def __len__(self): return len(self.items)\n",
                "    def __getitem__(self, i):\n",
                "        a,b,l = self.items[i]\n",
                "        im1 = torch.from_numpy(np.array(Image.open(f\"{self.root}/{a}\").resize((256,256)))).permute(2,0,1).float()/255\n",
                "        im2 = torch.from_numpy(np.array(Image.open(f\"{self.root}/{b}\").resize((256,256)))).permute(2,0,1).float()/255\n",
                "        lb = (torch.from_numpy(np.array(Image.open(f\"{self.root}/{l}\").convert('L').resize((256,256)))).float()/255>0.5).float().unsqueeze(0)\n",
                "        return im1, im2, lb\n",
                "\n",
                "train_ds = CDData(DATA_ROOT, '/kaggle/working/train.txt')\n",
                "val_ds = CDData(DATA_ROOT, '/kaggle/working/val.txt')\n",
                "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training\n",
                "from tqdm import tqdm\n",
                "from sklearn.metrics import f1_score\n",
                "import csv\n",
                "\n",
                "device = torch.device('cuda')\n",
                "model = SNUNet(32).to(device)\n",
                "opt = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
                "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, 100)\n",
                "\n",
                "train_ld = DataLoader(train_ds, 8, shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_ld = DataLoader(val_ds, 16, num_workers=2)\n",
                "\n",
                "os.makedirs('/kaggle/working/ckpt', exist_ok=True)\n",
                "log = open('/kaggle/working/ckpt/log.csv','w',newline='')\n",
                "writer = csv.writer(log)\n",
                "writer.writerow(['ep','loss','f1'])\n",
                "\n",
                "best = 0\n",
                "for ep in range(100):\n",
                "    model.train()\n",
                "    for x1,x2,y in tqdm(train_ld, desc=f\"Ep{ep+1}\", leave=False):\n",
                "        x1,x2,y = x1.to(device), x2.to(device), y.to(device)\n",
                "        opt.zero_grad()\n",
                "        out = model(x1,x2)\n",
                "        loss = F.binary_cross_entropy_with_logits(out,y) + (1 - (2*(torch.sigmoid(out)*y).sum()+1)/(torch.sigmoid(out).sum()+y.sum()+1))\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
                "        opt.step()\n",
                "    \n",
                "    model.eval()\n",
                "    f1s = []\n",
                "    with torch.no_grad():\n",
                "        for x1,x2,y in val_ld:\n",
                "            p = (torch.sigmoid(model(x1.to(device),x2.to(device)))>0.5).cpu().numpy().flatten()\n",
                "            f1s.append(f1_score(y.numpy().flatten(), p, zero_division=0))\n",
                "    f1 = sum(f1s)/len(f1s)\n",
                "    sched.step()\n",
                "    \n",
                "    print(f\"Ep {ep+1}: F1={f1:.4f}\")\n",
                "    writer.writerow([ep+1, loss.item(), f1])\n",
                "    log.flush()\n",
                "    \n",
                "    if f1 > best:\n",
                "        best = f1\n",
                "        torch.save(model.state_dict(), f'/kaggle/working/ckpt/best_{f1:.4f}.pth')\n",
                "        print(f\"  Saved!\")\n",
                "\n",
                "log.close()\n",
                "print(f\"\\nBest F1: {best:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize\n",
                "import matplotlib.pyplot as plt\n",
                "import glob\n",
                "\n",
                "ckpt = max(glob.glob('/kaggle/working/ckpt/best_*.pth'))\n",
                "model.load_state_dict(torch.load(ckpt))\n",
                "model.eval()\n",
                "\n",
                "fig, ax = plt.subplots(3,4,figsize=(12,9))\n",
                "for r in range(3):\n",
                "    x1,x2,y = val_ds[r*10]\n",
                "    with torch.no_grad():\n",
                "        p = (torch.sigmoid(model(x1.unsqueeze(0).cuda(), x2.unsqueeze(0).cuda()))>0.5).cpu().squeeze().numpy()\n",
                "    ax[r,0].imshow(x1.permute(1,2,0)); ax[r,1].imshow(x2.permute(1,2,0))\n",
                "    ax[r,2].imshow(y.squeeze(),cmap='gray'); ax[r,3].imshow(p,cmap='gray')\n",
                "    for c in range(4): ax[r,c].axis('off')\n",
                "ax[0,0].set_title('T1'); ax[0,1].set_title('T2'); ax[0,2].set_title('GT'); ax[0,3].set_title('Pred')\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/results.png')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}