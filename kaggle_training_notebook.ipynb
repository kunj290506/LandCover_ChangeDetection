{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ›°ï¸ SNUNet Change Detection - Kaggle Training\n",
                "\n",
                "**Before running:**\n",
                "1. Settings â†’ Accelerator â†’ **GPU T4 x2**\n",
                "2. Settings â†’ Internet â†’ **On**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SETUP ===\n",
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "import zipfile\n",
                "import urllib.request\n",
                "\n",
                "# Check GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "if device.type == 'cpu':\n",
                "    print(\"âš ï¸ WARNING: No GPU! Training will be very slow.\")\n",
                "    print(\"   Go to: Settings â†’ Accelerator â†’ GPU T4 x2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === DOWNLOAD DATASET ===\n",
                "DATA_DIR = '/kaggle/working/data'\n",
                "os.makedirs(DATA_DIR, exist_ok=True)\n",
                "\n",
                "# Check if data already exists\n",
                "train_dir = os.path.join(DATA_DIR, 'train', 'A')\n",
                "if os.path.exists(train_dir) and len(os.listdir(train_dir)) > 0:\n",
                "    print(f\"âœ… Dataset already exists: {len(os.listdir(train_dir))} train images\")\n",
                "else:\n",
                "    print(\"Downloading LEVIR-CD dataset...\")\n",
                "    \n",
                "    # Try multiple download sources\n",
                "    urls = [\n",
                "        'https://www.dropbox.com/s/18fb5jo07l0yqwg/LEVIR-CD-256.zip?dl=1',\n",
                "        'https://github.com/justchenhao/LEVIR-CD/releases/download/v1.0/LEVIR-CD-256.zip'\n",
                "    ]\n",
                "    \n",
                "    downloaded = False\n",
                "    for url in urls:\n",
                "        try:\n",
                "            print(f\"Trying: {url[:50]}...\")\n",
                "            urllib.request.urlretrieve(url, '/kaggle/working/levir.zip')\n",
                "            downloaded = True\n",
                "            print(\"âœ… Download complete!\")\n",
                "            break\n",
                "        except Exception as e:\n",
                "            print(f\"  Failed: {e}\")\n",
                "    \n",
                "    if downloaded:\n",
                "        print(\"Extracting...\")\n",
                "        with zipfile.ZipFile('/kaggle/working/levir.zip', 'r') as z:\n",
                "            z.extractall(DATA_DIR)\n",
                "        os.remove('/kaggle/working/levir.zip')\n",
                "        print(\"âœ… Extraction complete!\")\n",
                "    else:\n",
                "        print(\"âŒ Download failed. Creating synthetic data for demo...\")\n",
                "        # Create minimal synthetic data\n",
                "        for split in ['train', 'val', 'test']:\n",
                "            for sub in ['A', 'B', 'label']:\n",
                "                os.makedirs(os.path.join(DATA_DIR, split, sub), exist_ok=True)\n",
                "        \n",
                "        n_train, n_val = 100, 20\n",
                "        for split, n in [('train', n_train), ('val', n_val), ('test', n_val)]:\n",
                "            for i in range(n):\n",
                "                img = Image.fromarray(np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8))\n",
                "                img.save(os.path.join(DATA_DIR, split, 'A', f'{i:04d}.png'))\n",
                "                img.save(os.path.join(DATA_DIR, split, 'B', f'{i:04d}.png'))\n",
                "                mask = Image.fromarray(np.random.choice([0, 255], (256, 256)).astype(np.uint8))\n",
                "                mask.save(os.path.join(DATA_DIR, split, 'label', f'{i:04d}.png'))\n",
                "        print(\"âœ… Synthetic data created!\")\n",
                "\n",
                "# Find actual data path\n",
                "DATA_ROOT = DATA_DIR\n",
                "for root, dirs, files in os.walk(DATA_DIR):\n",
                "    if 'train' in dirs and 'A' in os.listdir(os.path.join(root, 'train')):\n",
                "        DATA_ROOT = root\n",
                "        break\n",
                "\n",
                "print(f\"\\nData root: {DATA_ROOT}\")\n",
                "for split in ['train', 'val', 'test']:\n",
                "    p = os.path.join(DATA_ROOT, split, 'A')\n",
                "    if os.path.exists(p):\n",
                "        print(f\"  {split}: {len(os.listdir(p))} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MODEL ===\n",
                "class ConvBlock(nn.Module):\n",
                "    def __init__(self, in_c, out_c):\n",
                "        super().__init__()\n",
                "        self.conv = nn.Sequential(\n",
                "            nn.Conv2d(in_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
                "            nn.Conv2d(out_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True)\n",
                "        )\n",
                "    def forward(self, x): return self.conv(x)\n",
                "\n",
                "class Attention(nn.Module):\n",
                "    def __init__(self, c):\n",
                "        super().__init__()\n",
                "        self.fc = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(c, c//8, 1), nn.ReLU(), nn.Conv2d(c//8, c, 1), nn.Sigmoid())\n",
                "    def forward(self, x): return x * self.fc(x)\n",
                "\n",
                "class SNUNet(nn.Module):\n",
                "    def __init__(self, base=32):\n",
                "        super().__init__()\n",
                "        c = base\n",
                "        self.enc1 = ConvBlock(3, c)\n",
                "        self.enc2 = ConvBlock(c, c*2)\n",
                "        self.enc3 = ConvBlock(c*2, c*4)\n",
                "        self.enc4 = ConvBlock(c*4, c*8)\n",
                "        self.enc5 = ConvBlock(c*8, c*16)\n",
                "        self.pool = nn.MaxPool2d(2)\n",
                "        \n",
                "        self.up4 = nn.ConvTranspose2d(c*16, c*8, 2, 2)\n",
                "        self.dec4 = ConvBlock(c*24, c*8)\n",
                "        self.att4 = Attention(c*8)\n",
                "        \n",
                "        self.up3 = nn.ConvTranspose2d(c*8, c*4, 2, 2)\n",
                "        self.dec3 = ConvBlock(c*12, c*4)\n",
                "        self.att3 = Attention(c*4)\n",
                "        \n",
                "        self.up2 = nn.ConvTranspose2d(c*4, c*2, 2, 2)\n",
                "        self.dec2 = ConvBlock(c*6, c*2)\n",
                "        self.att2 = Attention(c*2)\n",
                "        \n",
                "        self.up1 = nn.ConvTranspose2d(c*2, c, 2, 2)\n",
                "        self.dec1 = ConvBlock(c*3, c)\n",
                "        self.att1 = Attention(c)\n",
                "        \n",
                "        self.out = nn.Conv2d(c, 1, 1)\n",
                "        \n",
                "    def forward(self, x1, x2):\n",
                "        # Encoder\n",
                "        e11, e12 = self.enc1(x1), self.enc1(x2)\n",
                "        e21, e22 = self.enc2(self.pool(e11)), self.enc2(self.pool(e12))\n",
                "        e31, e32 = self.enc3(self.pool(e21)), self.enc3(self.pool(e22))\n",
                "        e41, e42 = self.enc4(self.pool(e31)), self.enc4(self.pool(e32))\n",
                "        e51, e52 = self.enc5(self.pool(e41)), self.enc5(self.pool(e42))\n",
                "        \n",
                "        # Decoder with skip connections\n",
                "        d = torch.abs(e51 - e52)\n",
                "        d = self.att4(self.dec4(torch.cat([self.up4(d), e41, e42], 1)))\n",
                "        d = self.att3(self.dec3(torch.cat([self.up3(d), e31, e32], 1)))\n",
                "        d = self.att2(self.dec2(torch.cat([self.up2(d), e21, e22], 1)))\n",
                "        d = self.att1(self.dec1(torch.cat([self.up1(d), e11, e12], 1)))\n",
                "        \n",
                "        return self.out(d)\n",
                "\n",
                "model = SNUNet(32).to(device)\n",
                "print(f\"âœ… Model: {sum(p.numel() for p in model.parameters()):,} parameters\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === DATASET ===\n",
                "class CDDataset(Dataset):\n",
                "    def __init__(self, root, split):\n",
                "        self.root = root\n",
                "        self.split = split\n",
                "        self.files = sorted([f for f in os.listdir(os.path.join(root, split, 'A')) if f.endswith('.png')])\n",
                "        \n",
                "    def __len__(self): return len(self.files)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        name = self.files[idx]\n",
                "        \n",
                "        img1 = np.array(Image.open(os.path.join(self.root, self.split, 'A', name)).convert('RGB').resize((256, 256)))\n",
                "        img2 = np.array(Image.open(os.path.join(self.root, self.split, 'B', name)).convert('RGB').resize((256, 256)))\n",
                "        label = np.array(Image.open(os.path.join(self.root, self.split, 'label', name)).convert('L').resize((256, 256)))\n",
                "        \n",
                "        img1 = torch.from_numpy(img1).permute(2, 0, 1).float() / 255.0\n",
                "        img2 = torch.from_numpy(img2).permute(2, 0, 1).float() / 255.0\n",
                "        label = (torch.from_numpy(label).float() / 255.0 > 0.5).float().unsqueeze(0)\n",
                "        \n",
                "        return img1, img2, label\n",
                "\n",
                "train_ds = CDDataset(DATA_ROOT, 'train')\n",
                "val_ds = CDDataset(DATA_ROOT, 'val') if os.path.exists(os.path.join(DATA_ROOT, 'val')) else CDDataset(DATA_ROOT, 'test')\n",
                "\n",
                "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"âœ… Train: {len(train_ds)} | Val: {len(val_ds)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LOSS & METRICS ===\n",
                "def hybrid_loss(pred, target):\n",
                "    # BCE\n",
                "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
                "    # Dice\n",
                "    pred_sig = torch.sigmoid(pred)\n",
                "    intersection = (pred_sig * target).sum()\n",
                "    dice = 1 - (2 * intersection + 1) / (pred_sig.sum() + target.sum() + 1)\n",
                "    return bce + dice\n",
                "\n",
                "def calc_f1(pred, target):\n",
                "    pred = (torch.sigmoid(pred) > 0.5).float()\n",
                "    tp = (pred * target).sum()\n",
                "    fp = (pred * (1 - target)).sum()\n",
                "    fn = ((1 - pred) * target).sum()\n",
                "    precision = tp / (tp + fp + 1e-8)\n",
                "    recall = tp / (tp + fn + 1e-8)\n",
                "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
                "    return f1.item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === TRAINING ===\n",
                "import csv\n",
                "\n",
                "EPOCHS = 100\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
                "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS)\n",
                "\n",
                "os.makedirs('/kaggle/working/checkpoints', exist_ok=True)\n",
                "log_file = open('/kaggle/working/checkpoints/log.csv', 'w', newline='')\n",
                "log_writer = csv.writer(log_file)\n",
                "log_writer.writerow(['epoch', 'train_loss', 'val_loss', 'val_f1'])\n",
                "\n",
                "best_f1 = 0\n",
                "patience = 0\n",
                "\n",
                "print(f\"Starting training for {EPOCHS} epochs...\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    # Train\n",
                "    model.train()\n",
                "    train_loss = 0\n",
                "    for x1, x2, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
                "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        out = model(x1, x2)\n",
                "        loss = hybrid_loss(out, y)\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "        optimizer.step()\n",
                "        \n",
                "        train_loss += loss.item()\n",
                "    train_loss /= len(train_loader)\n",
                "    \n",
                "    # Validate\n",
                "    model.eval()\n",
                "    val_loss, val_f1 = 0, 0\n",
                "    with torch.no_grad():\n",
                "        for x1, x2, y in val_loader:\n",
                "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
                "            out = model(x1, x2)\n",
                "            val_loss += hybrid_loss(out, y).item()\n",
                "            val_f1 += calc_f1(out, y)\n",
                "    val_loss /= len(val_loader)\n",
                "    val_f1 /= len(val_loader)\n",
                "    \n",
                "    scheduler.step()\n",
                "    \n",
                "    # Log\n",
                "    print(f\"Ep {epoch+1:3d} | Train: {train_loss:.4f} | Val: {val_loss:.4f} | F1: {val_f1:.4f}\")\n",
                "    log_writer.writerow([epoch+1, train_loss, val_loss, val_f1])\n",
                "    log_file.flush()\n",
                "    \n",
                "    # Save best\n",
                "    if val_f1 > best_f1:\n",
                "        best_f1 = val_f1\n",
                "        patience = 0\n",
                "        torch.save(model.state_dict(), '/kaggle/working/checkpoints/best_model.pth')\n",
                "        print(f\"      >> Saved best model (F1={val_f1:.4f})\")\n",
                "    else:\n",
                "        patience += 1\n",
                "        if patience >= 20:\n",
                "            print(\"Early stopping!\")\n",
                "            break\n",
                "\n",
                "log_file.close()\n",
                "print(\"-\" * 50)\n",
                "print(f\"âœ… Training complete! Best F1: {best_f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === VISUALIZATION ===\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "\n",
                "# Load best model\n",
                "model.load_state_dict(torch.load('/kaggle/working/checkpoints/best_model.pth'))\n",
                "model.eval()\n",
                "\n",
                "# Plot learning curves\n",
                "df = pd.read_csv('/kaggle/working/checkpoints/log.csv')\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "axes[0].plot(df['epoch'], df['train_loss'], label='Train')\n",
                "axes[0].plot(df['epoch'], df['val_loss'], label='Val')\n",
                "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\n",
                "axes[0].legend(); axes[0].grid(True)\n",
                "axes[0].set_title('Loss')\n",
                "\n",
                "axes[1].plot(df['epoch'], df['val_f1'], 'g-')\n",
                "axes[1].axhline(0.85, color='r', linestyle='--', label='Target')\n",
                "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('F1')\n",
                "axes[1].legend(); axes[1].grid(True)\n",
                "axes[1].set_title(f'F1 Score (Best: {df.val_f1.max():.4f})')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/learning_curves.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SAMPLE PREDICTIONS ===\n",
                "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
                "\n",
                "for row in range(3):\n",
                "    idx = row * 5\n",
                "    if idx >= len(val_ds):\n",
                "        break\n",
                "    x1, x2, y = val_ds[idx]\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        pred = torch.sigmoid(model(x1.unsqueeze(0).to(device), x2.unsqueeze(0).to(device)))\n",
                "        pred = (pred > 0.5).float().cpu().squeeze().numpy()\n",
                "    \n",
                "    axes[row, 0].imshow(x1.permute(1, 2, 0).numpy())\n",
                "    axes[row, 0].set_title('Time 1')\n",
                "    axes[row, 1].imshow(x2.permute(1, 2, 0).numpy())\n",
                "    axes[row, 1].set_title('Time 2')\n",
                "    axes[row, 2].imshow(y.squeeze().numpy(), cmap='gray')\n",
                "    axes[row, 2].set_title('Ground Truth')\n",
                "    axes[row, 3].imshow(pred, cmap='gray')\n",
                "    axes[row, 3].set_title('Prediction')\n",
                "    \n",
                "    for col in range(4):\n",
                "        axes[row, col].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/predictions.png')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nâœ… All done! Files saved in /kaggle/working/\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}