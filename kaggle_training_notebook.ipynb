{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ›°ï¸ SNUNet Change Detection - Kaggle Training\n",
                "\n",
                "**Before running:**\n",
                "1. Settings â†’ Accelerator â†’ **GPU T4 x2**\n",
                "2. Settings â†’ Internet â†’ **On**\n",
                "3. Add Data â†’ Search **\"levir-cd\"** â†’ Add dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SETUP ===\n",
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "if device.type == 'cpu':\n",
                "    print(\"âš ï¸ No GPU! Go to: Settings â†’ Accelerator â†’ GPU T4 x2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FIND OR CREATE DATASET ===\n",
                "DATA_ROOT = None\n",
                "\n",
                "# Search in Kaggle input directories\n",
                "if os.path.exists('/kaggle/input'):\n",
                "    for d in os.listdir('/kaggle/input'):\n",
                "        base = os.path.join('/kaggle/input', d)\n",
                "        for sub in ['', 'LEVIR-CD', 'levir-cd', 'LEVIR_CD']:\n",
                "            path = os.path.join(base, sub) if sub else base\n",
                "            if os.path.exists(path) and os.path.exists(os.path.join(path, 'train')):\n",
                "                DATA_ROOT = path\n",
                "                print(f\"âœ… Found dataset at: {DATA_ROOT}\")\n",
                "                break\n",
                "        if DATA_ROOT:\n",
                "            break\n",
                "\n",
                "# Create synthetic data if no dataset found\n",
                "if not DATA_ROOT:\n",
                "    print(\"âŒ Dataset not found. Creating synthetic demo data...\")\n",
                "    DATA_ROOT = '/kaggle/working/data'\n",
                "    for split in ['train', 'val', 'test']:\n",
                "        for sub in ['A', 'B', 'label']:\n",
                "            os.makedirs(os.path.join(DATA_ROOT, split, sub), exist_ok=True)\n",
                "    \n",
                "    for split, n in [('train', 200), ('val', 50), ('test', 50)]:\n",
                "        print(f\"  Creating {split}: {n} samples...\")\n",
                "        for i in range(n):\n",
                "            # Create semi-realistic synthetic change detection data\n",
                "            base = np.random.randint(50, 200, (256, 256, 3), dtype=np.uint8)\n",
                "            img1 = Image.fromarray(base)\n",
                "            img2 = Image.fromarray(base.copy())\n",
                "            \n",
                "            # Add random \"changed\" region\n",
                "            mask = np.zeros((256, 256), dtype=np.uint8)\n",
                "            x, y = np.random.randint(20, 200), np.random.randint(20, 200)\n",
                "            w, h = np.random.randint(20, 50), np.random.randint(20, 50)\n",
                "            mask[y:y+h, x:x+w] = 255\n",
                "            \n",
                "            img1.save(os.path.join(DATA_ROOT, split, 'A', f'{i:04d}.png'))\n",
                "            img2.save(os.path.join(DATA_ROOT, split, 'B', f'{i:04d}.png'))\n",
                "            Image.fromarray(mask).save(os.path.join(DATA_ROOT, split, 'label', f'{i:04d}.png'))\n",
                "    print(\"âœ… Synthetic data created!\")\n",
                "\n",
                "# Show dataset stats\n",
                "print(f\"\\nData root: {DATA_ROOT}\")\n",
                "for split in ['train', 'val', 'test']:\n",
                "    p = os.path.join(DATA_ROOT, split, 'A')\n",
                "    if os.path.exists(p):\n",
                "        print(f\"  {split}: {len(os.listdir(p))} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MODEL ===\n",
                "class ConvBlock(nn.Module):\n",
                "    def __init__(self, i, o):\n",
                "        super().__init__()\n",
                "        self.c = nn.Sequential(nn.Conv2d(i,o,3,padding=1), nn.BatchNorm2d(o), nn.ReLU(True),\n",
                "                               nn.Conv2d(o,o,3,padding=1), nn.BatchNorm2d(o), nn.ReLU(True))\n",
                "    def forward(self, x): return self.c(x)\n",
                "\n",
                "class Att(nn.Module):\n",
                "    def __init__(self, c):\n",
                "        super().__init__()\n",
                "        self.a = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(c,c//8,1), nn.ReLU(), nn.Conv2d(c//8,c,1), nn.Sigmoid())\n",
                "    def forward(self, x): return x * self.a(x)\n",
                "\n",
                "class SNUNet(nn.Module):\n",
                "    def __init__(self, c=32):\n",
                "        super().__init__()\n",
                "        self.e1,self.e2,self.e3,self.e4,self.e5 = ConvBlock(3,c), ConvBlock(c,c*2), ConvBlock(c*2,c*4), ConvBlock(c*4,c*8), ConvBlock(c*8,c*16)\n",
                "        self.pool = nn.MaxPool2d(2)\n",
                "        self.u4,self.d4,self.a4 = nn.ConvTranspose2d(c*16,c*8,2,2), ConvBlock(c*24,c*8), Att(c*8)\n",
                "        self.u3,self.d3,self.a3 = nn.ConvTranspose2d(c*8,c*4,2,2), ConvBlock(c*12,c*4), Att(c*4)\n",
                "        self.u2,self.d2,self.a2 = nn.ConvTranspose2d(c*4,c*2,2,2), ConvBlock(c*6,c*2), Att(c*2)\n",
                "        self.u1,self.d1,self.a1 = nn.ConvTranspose2d(c*2,c,2,2), ConvBlock(c*3,c), Att(c)\n",
                "        self.out = nn.Conv2d(c,1,1)\n",
                "\n",
                "    def forward(self, x1, x2):\n",
                "        e11,e12 = self.e1(x1), self.e1(x2)\n",
                "        e21,e22 = self.e2(self.pool(e11)), self.e2(self.pool(e12))\n",
                "        e31,e32 = self.e3(self.pool(e21)), self.e3(self.pool(e22))\n",
                "        e41,e42 = self.e4(self.pool(e31)), self.e4(self.pool(e32))\n",
                "        e51,e52 = self.e5(self.pool(e41)), self.e5(self.pool(e42))\n",
                "        d = torch.abs(e51-e52)\n",
                "        d = self.a4(self.d4(torch.cat([self.u4(d),e41,e42],1)))\n",
                "        d = self.a3(self.d3(torch.cat([self.u3(d),e31,e32],1)))\n",
                "        d = self.a2(self.d2(torch.cat([self.u2(d),e21,e22],1)))\n",
                "        d = self.a1(self.d1(torch.cat([self.u1(d),e11,e12],1)))\n",
                "        return self.out(d)\n",
                "\n",
                "model = SNUNet(32).to(device)\n",
                "print(f\"âœ… Model: {sum(p.numel() for p in model.parameters()):,} params\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === DATASET ===\n",
                "class CDData(Dataset):\n",
                "    def __init__(self, root, split):\n",
                "        self.root, self.split = root, split\n",
                "        a_dir = os.path.join(root, split, 'A')\n",
                "        self.files = sorted([f for f in os.listdir(a_dir) if f.endswith(('.png','.jpg'))])\n",
                "    def __len__(self): return len(self.files)\n",
                "    def __getitem__(self, i):\n",
                "        f = self.files[i]\n",
                "        im1 = np.array(Image.open(os.path.join(self.root,self.split,'A',f)).convert('RGB').resize((256,256)))\n",
                "        im2 = np.array(Image.open(os.path.join(self.root,self.split,'B',f)).convert('RGB').resize((256,256)))\n",
                "        lb = np.array(Image.open(os.path.join(self.root,self.split,'label',f)).convert('L').resize((256,256)))\n",
                "        return (torch.from_numpy(im1).permute(2,0,1).float()/255,\n",
                "                torch.from_numpy(im2).permute(2,0,1).float()/255,\n",
                "                (torch.from_numpy(lb).float()/255>0.5).float().unsqueeze(0))\n",
                "\n",
                "train_ds = CDData(DATA_ROOT, 'train')\n",
                "val_split = 'val' if os.path.exists(os.path.join(DATA_ROOT,'val','A')) else 'test'\n",
                "val_ds = CDData(DATA_ROOT, val_split)\n",
                "train_ld = DataLoader(train_ds, 8, shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_ld = DataLoader(val_ds, 16, num_workers=2)\n",
                "print(f\"âœ… Train: {len(train_ds)} | Val: {len(val_ds)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === TRAINING ===\n",
                "import csv\n",
                "\n",
                "def loss_fn(p, t):\n",
                "    bce = F.binary_cross_entropy_with_logits(p, t)\n",
                "    ps = torch.sigmoid(p)\n",
                "    dice = 1 - (2*(ps*t).sum()+1)/(ps.sum()+t.sum()+1)\n",
                "    return bce + dice\n",
                "\n",
                "def f1_score(p, t):\n",
                "    p = (torch.sigmoid(p)>0.5).float()\n",
                "    tp = (p*t).sum(); fp = (p*(1-t)).sum(); fn = ((1-p)*t).sum()\n",
                "    return (2*tp/(2*tp+fp+fn+1e-8)).item()\n",
                "\n",
                "EPOCHS = 100\n",
                "opt = torch.optim.AdamW(model.parameters(), 1e-4, weight_decay=1e-4)\n",
                "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, EPOCHS)\n",
                "\n",
                "os.makedirs('/kaggle/working/ckpt', exist_ok=True)\n",
                "log = open('/kaggle/working/ckpt/log.csv','w',newline='')\n",
                "w = csv.writer(log); w.writerow(['ep','tr_loss','va_loss','f1'])\n",
                "\n",
                "best, patience = 0, 0\n",
                "for ep in range(EPOCHS):\n",
                "    model.train(); tr_loss = 0\n",
                "    for x1,x2,y in tqdm(train_ld, desc=f\"Ep{ep+1}\", leave=False):\n",
                "        x1,x2,y = x1.to(device), x2.to(device), y.to(device)\n",
                "        opt.zero_grad(); out = model(x1,x2); loss = loss_fn(out,y)\n",
                "        loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(),1); opt.step()\n",
                "        tr_loss += loss.item()\n",
                "    tr_loss /= len(train_ld)\n",
                "    \n",
                "    model.eval(); va_loss, f1 = 0, 0\n",
                "    with torch.no_grad():\n",
                "        for x1,x2,y in val_ld:\n",
                "            x1,x2,y = x1.to(device), x2.to(device), y.to(device)\n",
                "            out = model(x1,x2); va_loss += loss_fn(out,y).item(); f1 += f1_score(out,y)\n",
                "    va_loss /= len(val_ld); f1 /= len(val_ld); sched.step()\n",
                "    \n",
                "    print(f\"Ep {ep+1:3d} | TrL:{tr_loss:.4f} | VaL:{va_loss:.4f} | F1:{f1:.4f}\")\n",
                "    w.writerow([ep+1,tr_loss,va_loss,f1]); log.flush()\n",
                "    \n",
                "    if f1 > best:\n",
                "        best, patience = f1, 0\n",
                "        torch.save(model.state_dict(), '/kaggle/working/ckpt/best.pth')\n",
                "        print(f\"   >> Saved (F1={f1:.4f})\")\n",
                "    else:\n",
                "        patience += 1\n",
                "        if patience >= 20: print(\"Early stop!\"); break\n",
                "\n",
                "log.close()\n",
                "print(f\"\\nâœ… Done! Best F1: {best:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === VISUALIZATION ===\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "\n",
                "model.load_state_dict(torch.load('/kaggle/working/ckpt/best.pth')); model.eval()\n",
                "\n",
                "df = pd.read_csv('/kaggle/working/ckpt/log.csv')\n",
                "fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
                "ax[0].plot(df['ep'],df['tr_loss'],label='Train'); ax[0].plot(df['ep'],df['va_loss'],label='Val')\n",
                "ax[0].legend(); ax[0].set_title('Loss'); ax[0].grid()\n",
                "ax[1].plot(df['ep'],df['f1'],'g-'); ax[1].axhline(0.85,color='r',linestyle='--')\n",
                "ax[1].set_title(f'F1 (Best:{df.f1.max():.4f})'); ax[1].grid()\n",
                "plt.tight_layout(); plt.savefig('/kaggle/working/curves.png'); plt.show()\n",
                "\n",
                "fig, ax = plt.subplots(3,4,figsize=(12,9))\n",
                "for r in range(3):\n",
                "    x1,x2,y = val_ds[r*5]\n",
                "    with torch.no_grad(): p = (torch.sigmoid(model(x1.unsqueeze(0).to(device),x2.unsqueeze(0).to(device)))>0.5).cpu().squeeze().numpy()\n",
                "    ax[r,0].imshow(x1.permute(1,2,0)); ax[r,1].imshow(x2.permute(1,2,0))\n",
                "    ax[r,2].imshow(y.squeeze(),cmap='gray'); ax[r,3].imshow(p,cmap='gray')\n",
                "    for c in range(4): ax[r,c].axis('off')\n",
                "ax[0,0].set_title('T1'); ax[0,1].set_title('T2'); ax[0,2].set_title('GT'); ax[0,3].set_title('Pred')\n",
                "plt.tight_layout(); plt.savefig('/kaggle/working/preds.png'); plt.show()\n",
                "print(\"\\nâœ… All done!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}