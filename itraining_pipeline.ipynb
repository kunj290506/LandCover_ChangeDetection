{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd747d76",
   "metadata": {},
   "source": [
    "# Land Cover Change Detection - ISRO Production Training\n",
    "\n",
    "## Complete Training Pipeline for Satellite Image Change Detection\n",
    "\n",
    "### Features:\n",
    "- SNUNet Architecture with CBAM Attention\n",
    "- Hybrid Loss (BCE + Dice + Focal + Tversky)\n",
    "- EMA (Exponential Moving Average) for stable predictions\n",
    "- 8x Test-Time Augmentation (TTA) for best accuracy\n",
    "- Real-time visualization and GPU monitoring\n",
    "- Auto file list generation from dataset structure\n",
    "- Save EVERY epoch model + Best model\n",
    "\n",
    "### Target: F1 Score > 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1924a7b",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tqdm matplotlib seaborn pandas scikit-learn albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070a69f",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import subprocess\n",
    "import copy\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import f1_score, jaccard_score, cohen_kappa_score, precision_score, recall_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LAND COVER CHANGE DETECTION - KAGGLE TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ebf05",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"All training hyperparameters\"\"\"\n",
    "    # DATA PATHS - KAGGLE DATASET\n",
    "    data_root: str = \"/kaggle/input/dataset1new\"\n",
    "    output_dir: str = \"/kaggle/working\"\n",
    "    checkpoint_dir: str = \"/kaggle/working/checkpoints\"\n",
    "    models_dir: str = \"/kaggle/working/models\"\n",
    "    patch_size: int = 256\n",
    "    \n",
    "    # TRAINING\n",
    "    batch_size: int = 16\n",
    "    num_workers: int = 2\n",
    "    pin_memory: bool = False\n",
    "    epochs: int = 50\n",
    "    learning_rate: float = 2e-4\n",
    "    weight_decay: float = 0.01\n",
    "    \n",
    "    # MODEL\n",
    "    base_channel: int = 32\n",
    "    use_attention: bool = True\n",
    "    \n",
    "    # LOSS WEIGHTS (Hybrid Loss)\n",
    "    bce_weight: float = 0.3\n",
    "    dice_weight: float = 0.3\n",
    "    focal_weight: float = 0.2\n",
    "    tversky_weight: float = 0.2\n",
    "    focal_gamma: float = 2.0\n",
    "    tversky_alpha: float = 0.3\n",
    "    tversky_beta: float = 0.7\n",
    "    \n",
    "    # ADVANCED TECHNIQUES\n",
    "    use_ema: bool = True\n",
    "    ema_decay: float = 0.999\n",
    "    use_tta: bool = True\n",
    "    tta_transforms: int = 8\n",
    "    gradient_clip: float = 1.0\n",
    "    \n",
    "    # MODEL SAVING\n",
    "    save_every_epoch: bool = True\n",
    "    save_best_only: bool = True\n",
    "    max_models_to_keep: int = 10\n",
    "    \n",
    "    # SCHEDULER\n",
    "    scheduler_type: str = \"cosine_warm\"\n",
    "    warmup_epochs: int = 3\n",
    "    T_0: int = 10\n",
    "    T_mult: int = 2\n",
    "    \n",
    "    # EARLY STOPPING\n",
    "    patience: int = 15\n",
    "    min_delta: float = 0.001\n",
    "    \n",
    "    # LOGGING\n",
    "    log_interval: int = 50\n",
    "    save_every: int = 5\n",
    "    \n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "config = Config()\n",
    "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(config.models_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nConfiguration loaded\")\n",
    "print(f\"Data Root: {config.data_root}\")\n",
    "print(f\"Device: {config.device}\")\n",
    "print(f\"Batch Size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Learning Rate: {config.learning_rate}\")\n",
    "print(f\"Save Every Epoch: {config.save_every_epoch}\")\n",
    "print(f\"Save Best Only: {config.save_best_only}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9982da",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: Auto-Generate File Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_lists(data_root, output_dir):\n",
    "    \"\"\"\n",
    "    Auto-generate train/val/test file lists from dataset structure.\n",
    "    Expected structure:\n",
    "    - data_root/train/A/, train/B/, train/label/\n",
    "    - data_root/val/A/, val/B/, val/label/\n",
    "    - data_root/test/A/, test/B/, test/label/\n",
    "    \"\"\"\n",
    "    splits = ['train', 'val', 'test']\n",
    "    file_lists = {}\n",
    "    \n",
    "    print(\"\\nGenerating file lists...\")\n",
    "    print(f\"Dataset root: {data_root}\")\n",
    "    \n",
    "    for split in splits:\n",
    "        a_dir = os.path.join(data_root, split, 'A')\n",
    "        \n",
    "        if not os.path.exists(a_dir):\n",
    "            print(f\"Warning: {split} folder not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        files = sorted(glob.glob(os.path.join(a_dir, '*.png')))\n",
    "        \n",
    "        list_path = os.path.join(output_dir, f'{split}_list.txt')\n",
    "        \n",
    "        with open(list_path, 'w') as f:\n",
    "            for img_path in files:\n",
    "                filename = os.path.basename(img_path)\n",
    "                line = f\"{split}/A/{filename} {split}/B/{filename} {split}/label/{filename}\\n\"\n",
    "                f.write(line)\n",
    "        \n",
    "        file_lists[split] = list_path\n",
    "        print(f\"{split}: {len(files)} samples -> {list_path}\")\n",
    "    \n",
    "    return file_lists\n",
    "\n",
    "file_lists = generate_file_lists(config.data_root, config.output_dir)\n",
    "\n",
    "config.train_list = file_lists.get('train', '')\n",
    "config.val_list = file_lists.get('val', '')\n",
    "config.test_list = file_lists.get('test', '')\n",
    "\n",
    "print(\"\\nFile lists generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96899f34",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: Enhanced Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"Manages model saving and loading with cleanup\"\"\"\n",
    "    def __init__(self, models_dir, max_models_to_keep=10):\n",
    "        self.models_dir = models_dir\n",
    "        self.max_models_to_keep = max_models_to_keep\n",
    "        self.saved_models = []\n",
    "        \n",
    "    def save_model(self, model, epoch, metrics, is_best=False, ema_shadow=None):\n",
    "        \"\"\"Save model with comprehensive metadata\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        if is_best:\n",
    "            filename = f\"BEST_model_epoch{epoch:03d}_f1_{metrics['f1']:.4f}_{timestamp}.pth\"\n",
    "        else:\n",
    "            filename = f\"model_epoch{epoch:03d}_f1_{metrics['f1']:.4f}_{timestamp}.pth\"\n",
    "        \n",
    "        filepath = os.path.join(self.models_dir, filename)\n",
    "        \n",
    "        save_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'f1': metrics['f1'],\n",
    "            'iou': metrics['iou'],\n",
    "            'precision': metrics['precision'],\n",
    "            'recall': metrics['recall'],\n",
    "            'loss': metrics['loss'],\n",
    "            'timestamp': timestamp,\n",
    "            'is_best': is_best\n",
    "        }\n",
    "        \n",
    "        if ema_shadow:\n",
    "            save_dict['ema_shadow'] = ema_shadow\n",
    "        \n",
    "        torch.save(save_dict, filepath)\n",
    "        self.saved_models.append((filepath, epoch, metrics['f1'], is_best))\n",
    "        \n",
    "        self._cleanup_old_models()\n",
    "        \n",
    "        return filepath\n",
    "    \n",
    "    def _cleanup_old_models(self):\n",
    "        \"\"\"Keep only recent models\"\"\"\n",
    "        if len(self.saved_models) > self.max_models_to_keep:\n",
    "            self.saved_models.sort(key=lambda x: x[1])\n",
    "            \n",
    "            models_to_remove = []\n",
    "            for model_info in self.saved_models:\n",
    "                if not model_info[3]:\n",
    "                    models_to_remove.append(model_info)\n",
    "                    if len(self.saved_models) - len(models_to_remove) <= self.max_models_to_keep:\n",
    "                        break\n",
    "            \n",
    "            for model_info in models_to_remove:\n",
    "                if os.path.exists(model_info[0]):\n",
    "                    os.remove(model_info[0])\n",
    "                    self.saved_models.remove(model_info)\n",
    "    \n",
    "    def get_best_model_path(self):\n",
    "        \"\"\"Get path to best model\"\"\"\n",
    "        best_models = [m for m in self.saved_models if m[3]]\n",
    "        if best_models:\n",
    "            best_models.sort(key=lambda x: x[2], reverse=True)\n",
    "            return best_models[0][0]\n",
    "        return None\n",
    "    \n",
    "    def list_models(self):\n",
    "        \"\"\"List all saved models\"\"\"\n",
    "        print(f\"\\nSaved Models ({len(self.saved_models)}):\")\n",
    "        print(\"-\" * 80)\n",
    "        for path, epoch, f1, is_best in sorted(self.saved_models, key=lambda x: x[1]):\n",
    "            status = \"[BEST]\" if is_best else \"\"\n",
    "            print(f\"Epoch {epoch:03d} | F1: {f1:.4f} {status} | {os.path.basename(path)}\")\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores average values\"\"\"\n",
    "    def __init__(self, name: str = \"\"):\n",
    "        self.name = name\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = self.avg = self.sum = self.count = 0\n",
    "        self.history = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.history.append(val)\n",
    "\n",
    "\n",
    "class EMA:\n",
    "    \"\"\"Exponential Moving Average for model weights\"\"\"\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        self._register()\n",
    "\n",
    "    def _register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_avg = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n",
    "                self.shadow[name] = new_avg.clone()\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "\n",
    "class GPUMonitor:\n",
    "    \"\"\"Real-time GPU monitoring\"\"\"\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "        \n",
    "    def get_stats(self) -> Dict:\n",
    "        if not torch.cuda.is_available():\n",
    "            return {'util': 0, 'mem_used': 0, 'mem_total': 0}\n",
    "        \n",
    "        mem_used = torch.cuda.memory_allocated() / 1e9\n",
    "        mem_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        \n",
    "        stats = {\n",
    "            'util': (mem_used / mem_total) * 100,\n",
    "            'mem_used': mem_used,\n",
    "            'mem_total': mem_total\n",
    "        }\n",
    "        self.history.append(stats)\n",
    "        return stats\n",
    "\n",
    "\n",
    "class TrainingLogger:\n",
    "    \"\"\"Comprehensive training logger with visualization\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.history = defaultdict(list)\n",
    "        self.epoch_times = []\n",
    "        self.gpu = GPUMonitor()\n",
    "        \n",
    "    def log_epoch(self, epoch, train_loss, val_metrics, epoch_time, lr):\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        self.history['epoch'].append(epoch)\n",
    "        self.history['train_loss'].append(train_loss)\n",
    "        self.history['val_loss'].append(val_metrics['loss'])\n",
    "        self.history['val_f1'].append(val_metrics['f1'])\n",
    "        self.history['val_iou'].append(val_metrics['iou'])\n",
    "        self.history['val_precision'].append(val_metrics['precision'])\n",
    "        self.history['val_recall'].append(val_metrics['recall'])\n",
    "        self.history['lr'].append(lr)\n",
    "        self.history['epoch_time'].append(epoch_time)\n",
    "        \n",
    "    def get_dataframe(self):\n",
    "        return pd.DataFrame(self.history)\n",
    "    \n",
    "    def estimate_remaining(self, current, total):\n",
    "        if not self.epoch_times:\n",
    "            return \"Calculating...\"\n",
    "        avg = np.mean(self.epoch_times)\n",
    "        remaining = (total - current) * avg\n",
    "        return str(timedelta(seconds=int(remaining)))\n",
    "\n",
    "print(\"Utility classes loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee9301",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6: Dataset with Advanced Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a519a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeDetectionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Optimized dataset for change detection with proper label handling.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, list_path, mode='train', patch_size=256):\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        self.files = []\n",
    "        with open(list_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 3:\n",
    "                    self.files.append(parts)\n",
    "        \n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "        \n",
    "        print(f\"{mode.upper()}: {len(self.files)} samples loaded\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_path = os.path.join(self.root_dir, self.files[idx][0])\n",
    "        img2_path = os.path.join(self.root_dir, self.files[idx][1])\n",
    "        label_path = os.path.join(self.root_dir, self.files[idx][2])\n",
    "\n",
    "        img1 = Image.open(img1_path).convert('RGB')\n",
    "        img2 = Image.open(img2_path).convert('RGB')\n",
    "        label = Image.open(label_path).convert('L')\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            img1, img2, label = self._augment(img1, img2, label)\n",
    "        \n",
    "        img1 = TF.normalize(TF.to_tensor(img1), self.mean, self.std)\n",
    "        img2 = TF.normalize(TF.to_tensor(img2), self.mean, self.std)\n",
    "        \n",
    "        label = TF.to_tensor(label)\n",
    "        if label.max() > 1:\n",
    "            label = (label > 0.5).float()\n",
    "        elif label.max() <= 1 and label.max() > 0.1:\n",
    "            label = (label > 0.5).float()\n",
    "        else:\n",
    "            label = (label > 0.001).float()\n",
    "\n",
    "        return {\n",
    "            'image1': img1,\n",
    "            'image2': img2,\n",
    "            'label': label,\n",
    "            'name': os.path.basename(self.files[idx][0])\n",
    "        }\n",
    "\n",
    "    def _augment(self, img1, img2, label):\n",
    "        \"\"\"Apply synchronized augmentations\"\"\"\n",
    "        if random.random() > 0.5:\n",
    "            img1 = TF.hflip(img1)\n",
    "            img2 = TF.hflip(img2)\n",
    "            label = TF.hflip(label)\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            img1 = TF.vflip(img1)\n",
    "            img2 = TF.vflip(img2)\n",
    "            label = TF.vflip(label)\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            angle = random.choice([90, 180, 270])\n",
    "            img1 = TF.rotate(img1, angle)\n",
    "            img2 = TF.rotate(img2, angle)\n",
    "            label = TF.rotate(label, angle)\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            brightness = random.uniform(0.8, 1.2)\n",
    "            contrast = random.uniform(0.8, 1.2)\n",
    "            img1 = TF.adjust_brightness(img1, brightness)\n",
    "            img1 = TF.adjust_contrast(img1, contrast)\n",
    "            img2 = TF.adjust_brightness(img2, brightness)\n",
    "            img2 = TF.adjust_contrast(img2, contrast)\n",
    "        \n",
    "        return img1, img2, label\n",
    "\n",
    "print(\"Dataset class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea02ba",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7: SNUNet Model with CBAM Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel attention module for CBAM\"\"\"\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        return self.sigmoid(avg_out + max_out)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial attention module for CBAM\"\"\"\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        combined = torch.cat([avg_out, max_out], dim=1)\n",
    "        return self.sigmoid(self.conv(combined))\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolutional Block Attention Module\"\"\"\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.ca(x)\n",
    "        x = x * self.sa(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Double convolution block with optional CBAM\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, use_cbam=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.cbam = CBAM(out_ch) if use_cbam else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.cbam:\n",
    "            x = self.cbam(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SNUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    SNUNet: Siamese Nested U-Net for Change Detection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, num_classes=1, base_ch=32, use_attention=True):\n",
    "        super().__init__()\n",
    "        C = base_ch\n",
    "        \n",
    "        self.conv0_0 = ConvBlock(in_ch, C)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv1_0 = ConvBlock(C, C*2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv2_0 = ConvBlock(C*2, C*4)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv3_0 = ConvBlock(C*4, C*8)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv4_0 = ConvBlock(C*8, C*16)\n",
    "        \n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv0_1 = ConvBlock(C*2 + C*4, C, use_cbam=use_attention)\n",
    "        self.conv1_1 = ConvBlock(C*4 + C*8, C*2, use_cbam=use_attention)\n",
    "        self.conv2_1 = ConvBlock(C*8 + C*16, C*4, use_cbam=use_attention)\n",
    "        self.conv3_1 = ConvBlock(C*16 + C*32, C*8, use_cbam=use_attention)\n",
    "        \n",
    "        self.conv0_2 = ConvBlock(C*2 + C*2 + C, C, use_cbam=use_attention)\n",
    "        self.conv1_2 = ConvBlock(C*4 + C*4 + C*2, C*2, use_cbam=use_attention)\n",
    "        self.conv2_2 = ConvBlock(C*8 + C*8 + C*4, C*4, use_cbam=use_attention)\n",
    "        \n",
    "        self.conv0_3 = ConvBlock(C*2 + C*2 + C + C, C, use_cbam=use_attention)\n",
    "        self.conv1_3 = ConvBlock(C*4 + C*4 + C*2 + C*2, C*2, use_cbam=use_attention)\n",
    "        \n",
    "        self.conv0_4 = ConvBlock(C*2 + C*2 + C + C + C, C)\n",
    "        \n",
    "        self.final = nn.Conv2d(C, num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_0_0 = self.conv0_0(x1)\n",
    "        x1_1_0 = self.conv1_0(self.pool1(x1_0_0))\n",
    "        x1_2_0 = self.conv2_0(self.pool2(x1_1_0))\n",
    "        x1_3_0 = self.conv3_0(self.pool3(x1_2_0))\n",
    "        x1_4_0 = self.conv4_0(self.pool4(x1_3_0))\n",
    "        \n",
    "        x2_0_0 = self.conv0_0(x2)\n",
    "        x2_1_0 = self.conv1_0(self.pool1(x2_0_0))\n",
    "        x2_2_0 = self.conv2_0(self.pool2(x2_1_0))\n",
    "        x2_3_0 = self.conv3_0(self.pool3(x2_2_0))\n",
    "        x2_4_0 = self.conv4_0(self.pool4(x2_3_0))\n",
    "        \n",
    "        x0_1 = self.conv0_1(torch.cat([x1_0_0, x2_0_0, self.up(x1_1_0), self.up(x2_1_0)], 1))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_1_0, x2_1_0, self.up(x1_2_0), self.up(x2_2_0)], 1))\n",
    "        x2_1 = self.conv2_1(torch.cat([x1_2_0, x2_2_0, self.up(x1_3_0), self.up(x2_3_0)], 1))\n",
    "        x3_1 = self.conv3_1(torch.cat([x1_3_0, x2_3_0, self.up(x1_4_0), self.up(x2_4_0)], 1))\n",
    "        \n",
    "        x0_2 = self.conv0_2(torch.cat([x1_0_0, x2_0_0, x0_1, self.up(x1_1)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_1_0, x2_1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x1_2_0, x2_2_0, x2_1, self.up(x3_1)], 1))\n",
    "        \n",
    "        x0_3 = self.conv0_3(torch.cat([x1_0_0, x2_0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_1_0, x2_1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        \n",
    "        x0_4 = self.conv0_4(torch.cat([x1_0_0, x2_0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "        \n",
    "        return self.final(x0_4)\n",
    "\n",
    "model = SNUNet(3, 1, config.base_channel, config.use_attention)\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "print(f\"SNUNet loaded: {param_count:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d13629",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 8: Hybrid Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss for segmentation\"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred).view(-1)\n",
    "        target = target.view(-1)\n",
    "        intersection = (pred * target).sum()\n",
    "        return 1 - (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for handling class imbalance\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
    "        pt = torch.exp(-bce)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    \"\"\"Tversky Loss for better FP/FN control\"\"\"\n",
    "    def __init__(self, alpha=0.3, beta=0.7, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred).view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        TP = (pred * target).sum()\n",
    "        FP = ((1 - target) * pred).sum()\n",
    "        FN = (target * (1 - pred)).sum()\n",
    "        \n",
    "        tversky = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
    "        return 1 - tversky\n",
    "\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid Loss combining BCE, Dice, Focal, and Tversky losses.\n",
    "    \"\"\"\n",
    "    def __init__(self, bce_w=0.3, dice_w=0.3, focal_w=0.2, tversky_w=0.2, \n",
    "                 focal_gamma=2.0, tversky_alpha=0.3, tversky_beta=0.7):\n",
    "        super().__init__()\n",
    "        self.bce_w = bce_w\n",
    "        self.dice_w = dice_w\n",
    "        self.focal_w = focal_w\n",
    "        self.tversky_w = tversky_w\n",
    "        \n",
    "        self.dice = DiceLoss()\n",
    "        self.focal = FocalLoss(gamma=focal_gamma)\n",
    "        self.tversky = TverskyLoss(alpha=tversky_alpha, beta=tversky_beta)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        dice = self.dice(pred, target)\n",
    "        focal = self.focal(pred, target)\n",
    "        tversky = self.tversky(pred, target)\n",
    "        \n",
    "        total = (self.bce_w * bce + self.dice_w * dice + \n",
    "                 self.focal_w * focal + self.tversky_w * tversky)\n",
    "        \n",
    "        return total\n",
    "\n",
    "print(\"Hybrid Loss loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d492b03",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 9: Visualization Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ecd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dashboard(logger, epoch, total_epochs, best_f1, checkpoint_dir):\n",
    "    \"\"\"Display comprehensive training dashboard\"\"\"\n",
    "    df = logger.get_dataframe()\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    fig.suptitle(f'Training Dashboard - Epoch {epoch}/{total_epochs} | Best F1: {best_f1:.4f}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(df['epoch'], df['train_loss'], 'b-', label='Train', lw=2)\n",
    "    ax1.plot(df['epoch'], df['val_loss'], 'r-', label='Val', lw=2)\n",
    "    ax1.fill_between(df['epoch'], df['train_loss'], df['val_loss'], alpha=0.2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Loss Curves')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(df['epoch'], df['val_f1'], 'g-', label='F1', lw=2, marker='o', ms=3)\n",
    "    ax2.plot(df['epoch'], df['val_iou'], 'm-', label='IoU', lw=2, marker='s', ms=3)\n",
    "    ax2.axhline(y=0.85, color='gold', ls='--', alpha=0.7, label='Target (0.85)')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.set_title('F1 & IoU')\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(df['epoch'], df['val_precision'], 'c-', label='Precision', lw=2)\n",
    "    ax3.plot(df['epoch'], df['val_recall'], 'y-', label='Recall', lw=2)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Score')\n",
    "    ax3.set_title('Precision & Recall')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax4.plot(df['epoch'], df['lr'], 'orange', lw=2)\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('LR')\n",
    "    ax4.set_title('Learning Rate Schedule')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_yscale('log')\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax5.bar(df['epoch'], df['epoch_time'], color='steelblue', alpha=0.7)\n",
    "    ax5.axhline(y=np.mean(df['epoch_time']), color='red', ls='--', label=f'Avg: {np.mean(df[\"epoch_time\"]):.1f}s')\n",
    "    ax5.set_xlabel('Epoch')\n",
    "    ax5.set_ylabel('Time (s)')\n",
    "    ax5.set_title('Epoch Duration')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    gpu = logger.gpu.get_stats()\n",
    "    remaining = logger.estimate_remaining(epoch, total_epochs)\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    TRAINING STATUS\n",
    "    {'='*30}\n",
    "    \n",
    "    Epoch: {epoch}/{total_epochs}\n",
    "    Best F1: {best_f1:.4f}\n",
    "    Current F1: {df['val_f1'].iloc[-1]:.4f}\n",
    "    Current IoU: {df['val_iou'].iloc[-1]:.4f}\n",
    "    \n",
    "    GPU Memory: {gpu['mem_used']:.1f}/{gpu['mem_total']:.1f} GB\n",
    "    ETA: {remaining}\n",
    "    \n",
    "    Train Loss: {df['train_loss'].iloc[-1]:.4f}\n",
    "    Val Loss: {df['val_loss'].iloc[-1]:.4f}\n",
    "    \"\"\"\n",
    "    ax6.text(0.1, 0.5, stats_text, fontsize=11, family='monospace', va='center',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(checkpoint_dir, 'dashboard.png'), dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6bb51",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 10: Training & Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device, config, ema=None):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    \n",
    "    for i, batch in enumerate(pbar):\n",
    "        img1 = batch['image1'].to(device, non_blocking=True)\n",
    "        img2 = batch['image2'].to(device, non_blocking=True)\n",
    "        label = batch['label'].to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(img1, img2)\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if config.gradient_clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if ema is not None:\n",
    "            ema.update()\n",
    "        \n",
    "        losses.update(loss.item(), img1.size(0))\n",
    "        \n",
    "        if i % config.log_interval == 0:\n",
    "            pbar.set_postfix({'Loss': f'{losses.avg:.4f}'})\n",
    "    \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device, use_tta=False):\n",
    "    \"\"\"Validate with optional TTA\"\"\"\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Validating', leave=False):\n",
    "            img1 = batch['image1'].to(device, non_blocking=True)\n",
    "            img2 = batch['image2'].to(device, non_blocking=True)\n",
    "            label = batch['label'].to(device, non_blocking=True)\n",
    "            \n",
    "            if use_tta:\n",
    "                outputs = []\n",
    "                for flip_h in [False, True]:\n",
    "                    for flip_v in [False, True]:\n",
    "                        for rot in [0, 90]:\n",
    "                            aug_img1, aug_img2 = img1, img2\n",
    "                            if flip_h:\n",
    "                                aug_img1 = torch.flip(aug_img1, [3])\n",
    "                                aug_img2 = torch.flip(aug_img2, [3])\n",
    "                            if flip_v:\n",
    "                                aug_img1 = torch.flip(aug_img1, [2])\n",
    "                                aug_img2 = torch.flip(aug_img2, [2])\n",
    "                            if rot == 90:\n",
    "                                aug_img1 = torch.rot90(aug_img1, 1, [2, 3])\n",
    "                                aug_img2 = torch.rot90(aug_img2, 1, [2, 3])\n",
    "                            \n",
    "                            out = model(aug_img1, aug_img2)\n",
    "                            \n",
    "                            if rot == 90:\n",
    "                                out = torch.rot90(out, -1, [2, 3])\n",
    "                            if flip_v:\n",
    "                                out = torch.flip(out, [2])\n",
    "                            if flip_h:\n",
    "                                out = torch.flip(out, [3])\n",
    "                            \n",
    "                            outputs.append(out)\n",
    "                \n",
    "                output = torch.mean(torch.stack(outputs), dim=0)\n",
    "            else:\n",
    "                output = model(img1, img2)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            losses.update(loss.item(), img1.size(0))\n",
    "            \n",
    "            pred = (torch.sigmoid(output) > 0.5).cpu().numpy().flatten().astype(int)\n",
    "            target = label.cpu().numpy().flatten().astype(int)\n",
    "            \n",
    "            all_preds.extend(pred)\n",
    "            all_targets.extend(target)\n",
    "    \n",
    "    preds = np.array(all_preds)\n",
    "    targets = np.array(all_targets)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': losses.avg,\n",
    "        'f1': f1_score(targets, preds, zero_division=0),\n",
    "        'iou': jaccard_score(targets, preds, zero_division=0),\n",
    "        'precision': precision_score(targets, preds, zero_division=0),\n",
    "        'recall': recall_score(targets, preds, zero_division=0),\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        metrics['kappa'] = cohen_kappa_score(targets, preds)\n",
    "    except:\n",
    "        metrics['kappa'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Training functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438753fc",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 11: Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    \"\"\"\n",
    "    Main training function with all advanced techniques.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    device = torch.device(config.device)\n",
    "    \n",
    "    print(\"\\nLoading datasets...\")\n",
    "    train_ds = ChangeDetectionDataset(config.data_root, config.train_list, 'train', config.patch_size)\n",
    "    val_ds = ChangeDetectionDataset(config.data_root, config.val_list, 'val', config.patch_size)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=config.pin_memory, \n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers, \n",
    "        pin_memory=config.pin_memory\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(train_ds)} samples ({len(train_loader)} batches)\")\n",
    "    print(f\"Val: {len(val_ds)} samples\")\n",
    "    \n",
    "    print(\"\\nInitializing model...\")\n",
    "    model = SNUNet(3, 1, config.base_channel, config.use_attention).to(device)\n",
    "    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    ema = EMA(model, config.ema_decay) if config.use_ema else None\n",
    "    if ema:\n",
    "        print(f\"EMA: Enabled (decay={config.ema_decay})\")\n",
    "    \n",
    "    model_manager = ModelManager(config.models_dir, config.max_models_to_keep)\n",
    "    \n",
    "    criterion = HybridLoss(\n",
    "        bce_w=config.bce_weight,\n",
    "        dice_w=config.dice_weight,\n",
    "        focal_w=config.focal_weight,\n",
    "        tversky_w=config.tversky_weight,\n",
    "        focal_gamma=config.focal_gamma,\n",
    "        tversky_alpha=config.tversky_alpha,\n",
    "        tversky_beta=config.tversky_beta\n",
    "    )\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.learning_rate, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=config.T_0, \n",
    "        T_mult=config.T_mult,\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nLoss: Hybrid (BCE:{config.bce_weight} + Dice:{config.dice_weight} + Focal:{config.focal_weight} + Tversky:{config.tversky_weight})\")\n",
    "    print(f\"Optimizer: AdamW (lr={config.learning_rate}, wd={config.weight_decay})\")\n",
    "    print(f\"Scheduler: CosineAnnealingWarmRestarts (T_0={config.T_0}, T_mult={config.T_mult})\")\n",
    "    \n",
    "    logger = TrainingLogger(config)\n",
    "    best_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING STARTED\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, config, ema)\n",
    "        \n",
    "        if ema:\n",
    "            ema.apply_shadow()\n",
    "        \n",
    "        val_metrics = validate(model, val_loader, criterion, device, use_tta=config.use_tta)\n",
    "        \n",
    "        if ema:\n",
    "            ema.restore()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        logger.log_epoch(epoch, train_loss, val_metrics, epoch_time, lr)\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            display_dashboard(logger, epoch, config.epochs, best_f1, config.checkpoint_dir)\n",
    "        \n",
    "        # Save model every epoch\n",
    "        if config.save_every_epoch:\n",
    "            ema_shadow = ema.shadow if ema else None\n",
    "            model_path = model_manager.save_model(model, epoch, val_metrics, is_best=False, ema_shadow=ema_shadow)\n",
    "            print(f\"Model saved: {os.path.basename(model_path)}\")\n",
    "        \n",
    "        # Check for best model\n",
    "        if val_metrics['f1'] > best_f1 + config.min_delta:\n",
    "            best_f1 = val_metrics['f1']\n",
    "            patience_counter = 0\n",
    "            \n",
    "            ema_shadow = ema.shadow if ema else None\n",
    "            best_path = model_manager.save_model(model, epoch, val_metrics, is_best=True, ema_shadow=ema_shadow)\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'best_f1': best_f1,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'ema_shadow': ema_shadow\n",
    "            }, os.path.join(config.checkpoint_dir, 'best_model.pth'))\n",
    "            \n",
    "            print(f\"\\nNEW BEST! F1: {best_f1:.4f} | IoU: {val_metrics['iou']:.4f}\")\n",
    "            print(f\"Best model saved to: {best_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}/{config.epochs} | \"\n",
    "              f\"Loss: {train_loss:.4f}/{val_metrics['loss']:.4f} | \"\n",
    "              f\"F1: {val_metrics['f1']:.4f} | IoU: {val_metrics['iou']:.4f} | \"\n",
    "              f\"LR: {lr:.2e} | Time: {epoch_time:.1f}s\")\n",
    "        \n",
    "        if patience_counter >= config.patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {config.patience} epochs)\")\n",
    "            break\n",
    "        \n",
    "        if epoch % config.save_every == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'f1': val_metrics['f1'],\n",
    "            }, os.path.join(config.checkpoint_dir, f'checkpoint_epoch_{epoch}.pth'))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBest F1 Score: {best_f1:.4f}\")\n",
    "    print(f\"Best Model: {config.checkpoint_dir}/best_model.pth\")\n",
    "    \n",
    "    model_manager.list_models()\n",
    "    \n",
    "    logger.get_dataframe().to_csv(os.path.join(config.checkpoint_dir, 'training_history.csv'), index=False)\n",
    "    print(f\"\\nTraining history: {config.checkpoint_dir}/training_history.csv\")\n",
    "    \n",
    "    return model, logger, best_f1, model_manager\n",
    "\n",
    "print(\"Main training function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17c691",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 12: START TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, logger, best_f1, model_manager = train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c28c7",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 13: Final Results & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82be749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(config.checkpoint_dir, 'training_history.csv'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_idx = df['val_f1'].idxmax()\n",
    "print(f\"\\nBest Epoch: {df.loc[best_idx, 'epoch']}\")\n",
    "print(f\"F1 Score:   {df.loc[best_idx, 'val_f1']:.4f}\")\n",
    "print(f\"IoU:        {df.loc[best_idx, 'val_iou']:.4f}\")\n",
    "print(f\"Precision:  {df.loc[best_idx, 'val_precision']:.4f}\")\n",
    "print(f\"Recall:     {df.loc[best_idx, 'val_recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining Statistics:\")\n",
    "print(f\"Total Epochs: {len(df)}\")\n",
    "print(f\"Avg Epoch Time: {df['epoch_time'].mean():.1f}s\")\n",
    "print(f\"Total Time: {df['epoch_time'].sum()/60:.1f} min\")\n",
    "\n",
    "print(f\"\\nProgress:\")\n",
    "print(f\"Initial F1: {df['val_f1'].iloc[0]:.4f}\")\n",
    "print(f\"Final F1:   {df['val_f1'].iloc[-1]:.4f}\")\n",
    "print(f\"Best F1:    {df['val_f1'].max():.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(df['epoch'], df['train_loss'], 'b-', label='Train')\n",
    "axes[0].plot(df['epoch'], df['val_loss'], 'r-', label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(df['epoch'], df['val_f1'], 'g-', label='F1', lw=2)\n",
    "axes[1].plot(df['epoch'], df['val_iou'], 'm-', label='IoU', lw=2)\n",
    "axes[1].axhline(y=0.85, color='gold', ls='--', label='Target')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('F1 & IoU')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "axes[2].plot(df['epoch'], df['val_precision'], 'c-', label='Precision')\n",
    "axes[2].plot(df['epoch'], df['val_recall'], 'y-', label='Recall')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Score')\n",
    "axes[2].set_title('Precision & Recall')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "axes[2].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config.checkpoint_dir, 'final_results.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nResults saved to {config.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa62028",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 14: Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.test_list and os.path.exists(config.test_list):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SET EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    best_model_path = model_manager.get_best_model_path()\n",
    "    if best_model_path:\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"\\nLoaded best model (F1: {checkpoint['f1']:.4f})\")\n",
    "    \n",
    "    test_ds = ChangeDetectionDataset(config.data_root, config.test_list, 'test', config.patch_size)\n",
    "    test_loader = DataLoader(test_ds, batch_size=config.batch_size, shuffle=False, \n",
    "                             num_workers=config.num_workers)\n",
    "    \n",
    "    device = torch.device(config.device)\n",
    "    criterion = HybridLoss()\n",
    "    test_metrics = validate(model, test_loader, criterion, device, use_tta=True)\n",
    "    \n",
    "    print(f\"\\nTest Results (with 8x TTA):\")\n",
    "    print(f\"F1 Score:   {test_metrics['f1']:.4f}\")\n",
    "    print(f\"IoU:        {test_metrics['iou']:.4f}\")\n",
    "    print(f\"Precision:  {test_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:     {test_metrics['recall']:.4f}\")\n",
    "    print(f\"Kappa:      {test_metrics['kappa']:.4f}\")\n",
    "else:\n",
    "    print(\"\\nTest list not found, skipping test evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ac7e0",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 15: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, device, num_samples=4):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        sample = dataset[idx]\n",
    "        img1 = sample['image1'].unsqueeze(0).to(device)\n",
    "        img2 = sample['image2'].unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(model(img1, img2))\n",
    "        \n",
    "        img1_vis = (sample['image1'] * std + mean).numpy().transpose(1, 2, 0)\n",
    "        img2_vis = (sample['image2'] * std + mean).numpy().transpose(1, 2, 0)\n",
    "        label_vis = sample['label'].squeeze().numpy()\n",
    "        pred_vis = pred.squeeze().cpu().numpy()\n",
    "        \n",
    "        img1_vis = np.clip(img1_vis, 0, 1)\n",
    "        img2_vis = np.clip(img2_vis, 0, 1)\n",
    "        \n",
    "        axes[i][0].imshow(img1_vis)\n",
    "        axes[i][0].set_title('Before')\n",
    "        axes[i][0].axis('off')\n",
    "        \n",
    "        axes[i][1].imshow(img2_vis)\n",
    "        axes[i][1].set_title('After')\n",
    "        axes[i][1].axis('off')\n",
    "        \n",
    "        axes[i][2].imshow(label_vis, cmap='gray')\n",
    "        axes[i][2].set_title('Ground Truth')\n",
    "        axes[i][2].axis('off')\n",
    "        \n",
    "        axes[i][3].imshow(pred_vis, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "        axes[i][3].set_title(f'Prediction')\n",
    "        axes[i][3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.checkpoint_dir, 'predictions.png'), dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "visualize_predictions(model, val_ds, torch.device(config.device), num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deeec07",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 16: Save Final Model for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = model_manager.get_best_model_path()\n",
    "if best_model_path:\n",
    "    final_save_path = os.path.join(config.checkpoint_dir, 'final_model_isro.pth')\n",
    "    \n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': checkpoint['model_state_dict'],\n",
    "        'model_config': {\n",
    "            'in_ch': 3,\n",
    "            'num_classes': 1,\n",
    "            'base_ch': config.base_channel,\n",
    "            'use_attention': config.use_attention\n",
    "        },\n",
    "        'best_f1': checkpoint['f1'],\n",
    "        'training_config': {\n",
    "            'epochs': config.epochs,\n",
    "            'batch_size': config.batch_size,\n",
    "            'learning_rate': config.learning_rate,\n",
    "            'loss': 'HybridLoss (BCE+Dice+Focal+Tversky)',\n",
    "            'ema': config.use_ema,\n",
    "            'tta': config.use_tta\n",
    "        }\n",
    "    }, final_save_path)\n",
    "    \n",
    "    print(f\"\\nFinal model saved: {final_save_path}\")\n",
    "    print(f\"Best F1: {checkpoint['f1']:.4f}\")\n",
    "    print(\"\\nFor ISRO submission, use this model file.\")\n",
    "else:\n",
    "    print(\"\\nNo best model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3513b1c",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 17: List Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOutput Files:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for f in sorted(os.listdir(config.checkpoint_dir)):\n",
    "    filepath = os.path.join(config.checkpoint_dir, f)\n",
    "    size = os.path.getsize(filepath) / (1024*1024)\n",
    "    print(f\"{f:<40} {size:.2f} MB\")\n",
    "\n",
    "print(\"\\nModels Directory:\")\n",
    "print(\"=\"*50)\n",
    "for f in sorted(os.listdir(config.models_dir))[:10]:\n",
    "    filepath = os.path.join(config.models_dir, f)\n",
    "    size = os.path.getsize(filepath) / (1024*1024)\n",
    "    print(f\"{f:<40} {size:.2f} MB\")\n",
    "if len(os.listdir(config.models_dir)) > 10:\n",
    "    print(f\"... and {len(os.listdir(config.models_dir)) - 10} more models\")\n",
    "\n",
    "print(\"\\nTraining complete! Download best_model.pth for deployment.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}